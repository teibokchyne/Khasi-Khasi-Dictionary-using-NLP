{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffc780e",
   "metadata": {},
   "source": [
    "# Train llm to find meanings\n",
    "* gemma3, t5-base, mistral, BART, T5-base-multi-sentence-doctor models do not work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a95ff",
   "metadata": {},
   "source": [
    "## Attempt to clean corpus using ChatGPT\n",
    "* Cost: â‚¹3000\n",
    "* Time: 70 minutes per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ebe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=\"\")\n",
    "\n",
    "# OCR cleaning function using OpenAI\n",
    "def ocr_cleaner_gpt(text):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in the Khasi language and OCR correction. Clean and correct the following sentence so that it makes clear and sensible meaning to a native Khasi speaker.\n",
    "\n",
    "    Instructions:\n",
    "    1. Fix OCR errors: correct misspellings, remove misread characters, and fix punctuation.\n",
    "    2. Convert the entire sentence to lowercase.\n",
    "    3. Remove any unnecessary metadata, page numbers, author tags, class numbers, or formatting artifacts that do not belong in natural language.\n",
    "    4. Keep proper names or culturally important terms, but only if they make sense in context.\n",
    "    5. Remove any words or phrases that disrupt the meaning or are likely OCR noise.\n",
    "\n",
    "    OCR text: \"{text}\"\n",
    "\n",
    "    Cleaned and corrected text:\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# File paths\n",
    "input_path = r\"outputs/full_sentences\"\n",
    "output_path = r\"outputs/ocr_cleaned_full_sentences\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for filename in os.listdir(input_path):\n",
    "    input_file_path = os.path.join(input_path, filename)\n",
    "    output_file_path = os.path.join(output_path, os.path.splitext(filename)[0] + \".txt\")\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as input_file, \\\n",
    "         open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                cleaned_text = ocr_cleaner_gpt(line)\n",
    "                output_file.write(cleaned_text + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {line}\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c87b7",
   "metadata": {},
   "source": [
    "## Attempt using ollama gemma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eca695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama  # Make sure you have `pip install ollama`\n",
    "\n",
    "# OCR cleaning function using Gemma via Ollama\n",
    "def ocr_cleaner_gemma_ollama(text):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in the Khasi language and OCR correction. Clean and correct the following sentence so that it makes clear and sensible meaning to a native Khasi speaker.\n",
    "\n",
    "Instructions:\n",
    "1. Fix OCR errors: correct misspellings, remove misread characters, and fix punctuation.\n",
    "2. Convert the entire sentence to lowercase.\n",
    "3. Remove any unnecessary metadata, page numbers, author tags, class numbers, or formatting artifacts that do not belong in natural language.\n",
    "4. Keep proper names or culturally important terms, but only if they make sense in context.\n",
    "5. Remove any words or phrases that disrupt the meaning or are likely OCR noise.\n",
    "\n",
    "OCR text: \"{text}\"\n",
    "\n",
    "Cleaned and corrected text:\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='gemma:3b',  # use your local model name\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with ollama: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# File paths\n",
    "input_path = r\"outputs/full_sentences\"\n",
    "output_path = r\"outputs/ocr_cleaned_full_sentences\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for filename in os.listdir(input_path):\n",
    "    input_file_path = os.path.join(input_path, filename)\n",
    "    output_file_path = os.path.join(output_path, os.path.splitext(filename)[0] + \".txt\")\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as input_file, \\\n",
    "         open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                cleaned_text = ocr_cleaner_gemma_ollama(line)\n",
    "                output_file.write(cleaned_text + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {line}\\n{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8359c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl  -  Rarrnwaro  Ace.\n",
    "\n",
    "# \"\"\"\n",
    "# You are an expert in the Khasi language and OCR correction. Clean and correct the following sentence so that it makes clear and sensible meaning to a native Khasi speaker.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Fix OCR errors: correct misspellings, remove misread characters, and fix punctuation.\n",
    "# 2. Convert the entire sentence to lowercase.\n",
    "# 3. Remove any unnecessary metadata, page numbers, author tags, class numbers, or formatting artifacts that do not belong in natural language.\n",
    "# 4. Keep proper names or culturally important terms, but only if they make sense in context.\n",
    "# 5. Remove any words or phrases that disrupt the meaning or are likely OCR noise.\n",
    "\n",
    "# OCR text: \"KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl  -  Rarrnwaro  Ace.\"\n",
    "\n",
    "# Cleaned and corrected text:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a17f0d",
   "metadata": {},
   "source": [
    "## Attempt using bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389b56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:    You are an expert in the Khasi language and OCR correction. Please use the following instructions to correct the following sentence: \"KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl  -  Rarrnwaro  Ace.\" OCR text: \"Ki Jingthoh HALor Ka KOLshor BAD Ka POLITIK\"   Cleaned and corrected text: 1. Fix OCR errors: correct misspellings, remove misread characters, and fix punctuation. 2. Convert the entire sentence to lowercase. 3. Remove any unnecessary metadata, page numbers, author tags, class numbers, or formatting artifacts that do not belong in natural language. 4. Keep proper names or culturally important terms, but only if they make sense in context. 5. Clean up any typos or grammatical errors.   Instructions:  *   1. Correct OCR error:  #   2. Correct typos: #   3. Fix punctuation: .#   4. Remove unnecessary formatting artifacts: :#   5. Remove words or phrases that are likely OCR noise. # 1. Clean and correct: ______________________________ _____________________________ ____________________________ _______________________________ __________________________ ___________________________ _________________________ _______________________________________ ______________ _____________ ____________ _______________\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import torch\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "model_name = \"facebook/bart-large\"  # BART model suitable for your system\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to clean the OCR text using BART\n",
    "def ocr_cleaner_bart(text):\n",
    "    input_text = f\"fix: \"{text}\"\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    \n",
    "    # Generate output\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=512, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the generated text\n",
    "    corrected_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return corrected_text.strip()\n",
    "\n",
    "# Example usage\n",
    "text = \"KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl  -  Rarrnwaro  Ace.\"\n",
    "print(ocr_cleaner_bart(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647e85a",
   "metadata": {},
   "source": [
    "## Attempt cleaning manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8226def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl - Rarrnwaro Ace.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # Remove page numbers like \"Page 23\", \"[23]\", or just \"23\" at line start/end\n",
    "    text = re.sub(r'\\bPage\\s*\\d+\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'^\\s*\\[?\\d+\\]?\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove lines that are mostly uppercase and short (headers/footers)\n",
    "    text = re.sub(r'^[A-Z\\s,.\\-]{5,50}$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove author/editor tags\n",
    "    text = re.sub(r'(?:^|\\n)[â€“â€”-]?\\s*(By|Edited by|Editor|Author)\\s+[\\w\\s.]+\\n?', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove class or catalog numbers (e.g. \"Class 491.25\", \"Dewey 899.233\")\n",
    "    text = re.sub(r'\\b(Class|Dewey|ISBN)\\s*\\d+(\\.\\d+)?\\b', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Fix hyphenated words broken across lines\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "    # Fix broken sentences across lines\n",
    "    text = re.sub(r'(?<!\\n)\\n(?![\\n])', ' ', text)\n",
    "\n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "\n",
    "    # Normalize extra spaces\n",
    "    text = re.sub(r'[ \\t]{2,}', ' ', text)\n",
    "\n",
    "    # Strip overall leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(clean_text(\"KI JINGTHOH HALOR KA KOLSHOR BAD KA POLITIK O Da U Hipshon Roy Kharshjing 1993 Becas 10380 8 Class No RAS-AD Wo TADA Author SAS NES KR Title a AN ke NN Borrower'sl  -  Rarrnwaro  Ace.\"))\n",
    "    # with open(\"input_raw.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    #     raw = f.read()\n",
    "\n",
    "    # cleaned = clean_text(raw)\n",
    "\n",
    "    # with open(\"output_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(cleaned)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khasi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
